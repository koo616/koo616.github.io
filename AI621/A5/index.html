<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>AI621 HW 1 - Gyojung Gu</title>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    </head>
    <body>
        <div class="container" style="margin-top:20px;">
            <div class="row">
                <div class="col-md-12">
                    <center>
                        <h1>Homework Assignment 5</h1>
                        <h3>AI621</h3>
                        <h2>20218177 Gyojung Gu</h2>
                    </center>
                    <hr>

                    <h2>Initials (5 points)</h2>
                    I make an array 'L(u, v, s, t, c)' and fill it with an image corresponding each u and v.
                    A width and a height size of an image is obtained by dividing a lightfield image's shape by lenslet size. 
                    '::' index in python performs same function in Matlab.
                    To make sure the array is right, a visualized image at (u=8, v=8) is attached below.
                    <center>
                    <figure class="figure">
                        <img src="./figs/1_initials.png" class="figure-img img-fluid" style="width:50%">
                        <figurecaption>
                            <center>
                                Fig 1. Code for initials.
                            </center>
                        </figurecaption>
                    </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/u8_v8.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 2. A visualized image at (u=8, v=8).
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    <hr>
                    <h2>Sub-aperture views (20 points)</h2>
                    Using the code below, a mosaic image of sub-aperture views can be obtained and I find that it is same as the expected result in homework pdf.
                    The mosaic image file is too big to attach on my github.io website, so I upload it on KLMS.
                    <center>
                        <figure class="figure">
                            <img src="./figs/2_sub-aperture.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 3. Code for making a mosaic image.
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    <hr>
                    <h2>Refocusing and focal-stack generation (40 points)</h2>
                    Before implementing Equation 2, I tested Equantion 1 first and the result is same as the left image of Figure 3 in homwork pdf.
                    <center>
                        <figure class="figure">
                            <img src="./figs/3_test.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/test_eq2.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 4. Code for Equation 1 and the result image.
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    I implement function 'I' without 'c' parameter because three color channels can be computed simultaneously.
                    RGB pixel values on a refocused image at 'd' can be obtained using function 'I'.
                    Refocused images with various 'd' are saved and stacked in a dictionary for solving the next problem.
                    Code and the images of different refocusings is shown below.
                    <center>
                        <figure class="figure">
                            <img src="./figs/3_refocus.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 5. Code for refocusing.
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    <center>
                        <figure class="figure">
                            <img src="./figs/eq2_0.1.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/eq2_0.3.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/eq2_0.5.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/eq2_0.7.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/eq2_0.9.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/eq2_1.1.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 6. The images of different refocusings. ('d' -> 0.1, 0.3, 0.5, 0.7, 0.9 and 1.1)
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    <hr>
                    <h2>All-focus image and depth from defocus (35 points)</h2>
                    <center>
                        <figure class="figure">
                            <img src="./figs/4_allfocus.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 7. Code for all-focus image and depth
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    Using a focal stack I made in previous problem, I implement a algorithm depicted in homework pdf.
                    Y channel(luminance channel) can be extracted from XYZ color space.
                    In 'cv2.GaussianBlur' function, I only choose sigma parameter because kernel size can be determined by sigma.
                    I explore some pairs of sigma parameters for two Gaussian filters and I find that all-focus RGB images are similar regardless of sigmas.
                    However, in depth maps, increasing sigma2 shows more smoother results. Judging from this experiment, I think a sigma pair (3, 5) works best.
                    The images for three pairs of sigma are shown below.
                    <center>
                        <figure class="figure">
                            <img src="./figs/all_focus_s1_1_s2_3.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/depth_s1_1_s2_3.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/all_focus_s1_3_s2_3.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/depth_s1_3_s2_3.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/all_focus_s1_3_s2_5.png" class="figure-img img-fluid" style="width:50%">
                            <img src="./figs/depth_s1_3_s2_5.png" class="figure-img img-fluid" style="width:50%">
                            <figurecaption>
                                <center>
                                    Fig 8. All-focus images and depth maps of three sigma pairs. [1, 3], [3, 3] and [3, 5].
                                </center>
                            </figurecaption>
                        </figure>
                    </center>
                    <br><br><br>
                </div>
            </div>
        </div>
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </body>
</html>